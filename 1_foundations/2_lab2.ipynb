{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key not set (and this is optional)\n",
      "Google API Key not set (and this is optional)\n",
      "DeepSeek API Key not set (and this is optional)\n",
      "Groq API Key not set (and this is optional)\n"
     ]
    }
   ],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How do you reconcile the tension between individual autonomy and collective welfare in the context of ethical decision-making in artificial intelligence?\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reconciling the tension between individual autonomy and collective welfare in ethical decision-making related to artificial intelligence (AI) is a complex challenge that requires a multidimensional approach. Here are several strategies to navigate this tension:\n",
       "\n",
       "1. **Value Alignment**: Develop AI systems that are aligned with human values. This can involve engaging diverse stakeholders in the design and deployment phases to ensure that the systems respect individual autonomy while promoting collective welfare. Understanding the values of both individuals and communities can help create a balanced approach.\n",
       "\n",
       "2. **Transparent Decision-Making**: Foster transparency in AI systems to allow individuals to understand how decisions are made. When people are informed about how their data is used and how decisions affect them, they may feel more empowered and autonomous, thus reducing friction with collective measures that benefit society.\n",
       "\n",
       "3. **Informed Consent**: Implement robust informed consent mechanisms that respect individual autonomy while also outlining how individual choices contribute to collective welfare. This involves providing clear information about how AI systems function, what data they use, and how decisions impact both individuals and the broader community.\n",
       "\n",
       "4. **Adaptive Policies**: Create adaptive regulatory frameworks that balance individual rights and collective needs. This can include policies that allow for flexibility and adaptation based on societal changes, technological advancements, and social norms. Such frameworks should promote both personal agency and communal benefits.\n",
       "\n",
       "5. **Participatory Design**: Use participatory design methods that involve communities in the development of AI systems. This approach ensures that the perspectives and needs of individuals are considered alongside collective interests, leading to solutions that are more widely accepted and beneficial.\n",
       "\n",
       "6. **Contextual Ethics**: Employ context-sensitive ethical frameworks that consider the specific circumstances of each decision. For instance, in healthcare AI, protecting individual patient autonomy might be prioritized if the individual's health is at stake. In other contexts, like public safety, the collective good may take precedence.\n",
       "\n",
       "7. **Balancing Risks and Benefits**: Evaluate the risks and benefits of AI applications holistically. This includes assessing how individual rights might be infringed upon by actions aimed at benefiting the community, and vice versa. A careful risk-benefit analysis can help to strike a balance that respects both sides.\n",
       "\n",
       "8. **Education and Awareness**: Promote understanding of both individual rights and the importance of collective welfare. By educating users and stakeholders about the interconnectedness of personal and societal interests, individuals may become more receptive to collective welfare initiatives.\n",
       "\n",
       "9. **Multi-Stakeholder Dialogue**: Foster ongoing dialogue among various stakeholders, including ethicists, technologists, policymakers, and the public. This dialogue can help identify potential conflicts and develop collaborative solutions that uphold both individual autonomy and collective welfare.\n",
       "\n",
       "10. **Ethical AI Frameworks**: Develop and implement ethical frameworks for AI that guide decision-making processes. Such frameworks can help navigate ethical dilemmas by providing guidelines that prioritize both individual autonomy and the consideration of collective impacts.\n",
       "\n",
       "By incorporating these strategies, we can work towards an ethical framework for AI that respects personal agency while recognizing the importance of the greater good, ultimately aiming for solutions that benefit both individuals and society as a whole."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The API we know well\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropic has a slightly different API, and Max Tokens is required\n",
    "\n",
    "model_name = \"claude-3-7-sonnet-latest\"\n",
    "\n",
    "claude = Anthropic()\n",
    "response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n",
    "answer = response.content[0].text\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "model_name = \"deepseek-chat\"\n",
    "\n",
    "response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama3.2:1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reconciling individual autonomy with collective welfare is a crucial challenge in the development and deployment of artificial intelligence (AI). As AI systems become more complex and influential, there is growing concern about how to balance individual rights and freedoms with the need for collective well-being. Here are some key considerations to help reconcile these tensions:\n",
       "\n",
       "**Individual Autonomy:**\n",
       "\n",
       "1. **Respect for human dignity**: Recognize that individuals have inherent value and dignity, which should be respected in decision-making processes.\n",
       "2. **Consent and informed consent**: Ensure that individuals provide informed and voluntary consent for AI systems to process their data, decisions, or actions.\n",
       "3. **Capacity and cognitive abilities**: Consider the capabilities and limitations of individuals, particularly those with disabilities, when making decisions about AI-driven outcomes.\n",
       "\n",
       "**Collective Welfare:**\n",
       "\n",
       "1. **Common good approach**: Prioritize collective interests over individual goals, recognizing that the well-being of society as a whole is often impacted by AI systems.\n",
       "2. **Transparency and accountability**: Foster transparency in decision-making processes to ensure that individuals understand how their choices are being made and why they were made.\n",
       "3. **Value alignment**: Implement mechanisms to align AI objectives with human values, such as fairness, equality, and justice.\n",
       "\n",
       "**Strategies for Reconciling Autonomy and Welfare:**\n",
       "\n",
       "1. **Distributed design**: Design AI systems with distributed decision-making processes that consider diverse perspectives and expertise, reducing the dominance of individual views.\n",
       "2. **Human oversight and feedback**: Integrate human evaluators into the decision-making process to provide contextually relevant feedback and ensure accountability.\n",
       "3. **Explainability and interpretable AI**: Develop AI systems that can explain their reasoning processes and outcomes, empowering individuals to understand their decisions and take action if necessary.\n",
       "4. **Collaborative governance**: Establish collaborative governance frameworks that involve stakeholders from diverse backgrounds, including experts in ethics, human rights, and relevant regulatory bodies.\n",
       "5. **Risk assessment and mitigation**: Conduct thorough risk assessments for AI systems and develop strategies to mitigate potential harms, ensuring that collective welfare is protected while maintaining individual autonomy.\n",
       "\n",
       "**Key Challenges and Open Questions:**\n",
       "\n",
       "1. **Defining and measuring collective welfare**: Identify metrics and benchmarks to evaluate the impact of AI on society.\n",
       "2. **Balancing innovation with regulation**: Balance the benefits of technological advancements with concerns about individual privacy, security, and accountability.\n",
       "3. **Addressing competing values**: Engage in ongoing dialogue across different societal sectors (e.g., tech companies, academia, policymakers) to foster common understanding of ethical issues related to AI-driven outcomes.\n",
       "\n",
       "In conclusion, reconciling individual autonomy and collective welfare in the context of ethical decision-making in AI requires careful consideration of diverse perspectives, expertise, and values. By adopting strategies such as distributed design, human oversight, and explainability, we can build more equitable and responsible AI systems that prioritize both individual rights and collective well-being."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.2:1b\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt-4o-mini', 'llama3.2:1b']\n",
      "[\"Reconciling the tension between individual autonomy and collective welfare in ethical decision-making related to artificial intelligence (AI) is a complex challenge that requires a multidimensional approach. Here are several strategies to navigate this tension:\\n\\n1. **Value Alignment**: Develop AI systems that are aligned with human values. This can involve engaging diverse stakeholders in the design and deployment phases to ensure that the systems respect individual autonomy while promoting collective welfare. Understanding the values of both individuals and communities can help create a balanced approach.\\n\\n2. **Transparent Decision-Making**: Foster transparency in AI systems to allow individuals to understand how decisions are made. When people are informed about how their data is used and how decisions affect them, they may feel more empowered and autonomous, thus reducing friction with collective measures that benefit society.\\n\\n3. **Informed Consent**: Implement robust informed consent mechanisms that respect individual autonomy while also outlining how individual choices contribute to collective welfare. This involves providing clear information about how AI systems function, what data they use, and how decisions impact both individuals and the broader community.\\n\\n4. **Adaptive Policies**: Create adaptive regulatory frameworks that balance individual rights and collective needs. This can include policies that allow for flexibility and adaptation based on societal changes, technological advancements, and social norms. Such frameworks should promote both personal agency and communal benefits.\\n\\n5. **Participatory Design**: Use participatory design methods that involve communities in the development of AI systems. This approach ensures that the perspectives and needs of individuals are considered alongside collective interests, leading to solutions that are more widely accepted and beneficial.\\n\\n6. **Contextual Ethics**: Employ context-sensitive ethical frameworks that consider the specific circumstances of each decision. For instance, in healthcare AI, protecting individual patient autonomy might be prioritized if the individual's health is at stake. In other contexts, like public safety, the collective good may take precedence.\\n\\n7. **Balancing Risks and Benefits**: Evaluate the risks and benefits of AI applications holistically. This includes assessing how individual rights might be infringed upon by actions aimed at benefiting the community, and vice versa. A careful risk-benefit analysis can help to strike a balance that respects both sides.\\n\\n8. **Education and Awareness**: Promote understanding of both individual rights and the importance of collective welfare. By educating users and stakeholders about the interconnectedness of personal and societal interests, individuals may become more receptive to collective welfare initiatives.\\n\\n9. **Multi-Stakeholder Dialogue**: Foster ongoing dialogue among various stakeholders, including ethicists, technologists, policymakers, and the public. This dialogue can help identify potential conflicts and develop collaborative solutions that uphold both individual autonomy and collective welfare.\\n\\n10. **Ethical AI Frameworks**: Develop and implement ethical frameworks for AI that guide decision-making processes. Such frameworks can help navigate ethical dilemmas by providing guidelines that prioritize both individual autonomy and the consideration of collective impacts.\\n\\nBy incorporating these strategies, we can work towards an ethical framework for AI that respects personal agency while recognizing the importance of the greater good, ultimately aiming for solutions that benefit both individuals and society as a whole.\", 'Reconciling individual autonomy with collective welfare is a crucial challenge in the development and deployment of artificial intelligence (AI). As AI systems become more complex and influential, there is growing concern about how to balance individual rights and freedoms with the need for collective well-being. Here are some key considerations to help reconcile these tensions:\\n\\n**Individual Autonomy:**\\n\\n1. **Respect for human dignity**: Recognize that individuals have inherent value and dignity, which should be respected in decision-making processes.\\n2. **Consent and informed consent**: Ensure that individuals provide informed and voluntary consent for AI systems to process their data, decisions, or actions.\\n3. **Capacity and cognitive abilities**: Consider the capabilities and limitations of individuals, particularly those with disabilities, when making decisions about AI-driven outcomes.\\n\\n**Collective Welfare:**\\n\\n1. **Common good approach**: Prioritize collective interests over individual goals, recognizing that the well-being of society as a whole is often impacted by AI systems.\\n2. **Transparency and accountability**: Foster transparency in decision-making processes to ensure that individuals understand how their choices are being made and why they were made.\\n3. **Value alignment**: Implement mechanisms to align AI objectives with human values, such as fairness, equality, and justice.\\n\\n**Strategies for Reconciling Autonomy and Welfare:**\\n\\n1. **Distributed design**: Design AI systems with distributed decision-making processes that consider diverse perspectives and expertise, reducing the dominance of individual views.\\n2. **Human oversight and feedback**: Integrate human evaluators into the decision-making process to provide contextually relevant feedback and ensure accountability.\\n3. **Explainability and interpretable AI**: Develop AI systems that can explain their reasoning processes and outcomes, empowering individuals to understand their decisions and take action if necessary.\\n4. **Collaborative governance**: Establish collaborative governance frameworks that involve stakeholders from diverse backgrounds, including experts in ethics, human rights, and relevant regulatory bodies.\\n5. **Risk assessment and mitigation**: Conduct thorough risk assessments for AI systems and develop strategies to mitigate potential harms, ensuring that collective welfare is protected while maintaining individual autonomy.\\n\\n**Key Challenges and Open Questions:**\\n\\n1. **Defining and measuring collective welfare**: Identify metrics and benchmarks to evaluate the impact of AI on society.\\n2. **Balancing innovation with regulation**: Balance the benefits of technological advancements with concerns about individual privacy, security, and accountability.\\n3. **Addressing competing values**: Engage in ongoing dialogue across different societal sectors (e.g., tech companies, academia, policymakers) to foster common understanding of ethical issues related to AI-driven outcomes.\\n\\nIn conclusion, reconciling individual autonomy and collective welfare in the context of ethical decision-making in AI requires careful consideration of diverse perspectives, expertise, and values. By adopting strategies such as distributed design, human oversight, and explainability, we can build more equitable and responsible AI systems that prioritize both individual rights and collective well-being.']\n"
     ]
    }
   ],
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competitor: gpt-4o-mini\n",
      "\n",
      "Reconciling the tension between individual autonomy and collective welfare in ethical decision-making related to artificial intelligence (AI) is a complex challenge that requires a multidimensional approach. Here are several strategies to navigate this tension:\n",
      "\n",
      "1. **Value Alignment**: Develop AI systems that are aligned with human values. This can involve engaging diverse stakeholders in the design and deployment phases to ensure that the systems respect individual autonomy while promoting collective welfare. Understanding the values of both individuals and communities can help create a balanced approach.\n",
      "\n",
      "2. **Transparent Decision-Making**: Foster transparency in AI systems to allow individuals to understand how decisions are made. When people are informed about how their data is used and how decisions affect them, they may feel more empowered and autonomous, thus reducing friction with collective measures that benefit society.\n",
      "\n",
      "3. **Informed Consent**: Implement robust informed consent mechanisms that respect individual autonomy while also outlining how individual choices contribute to collective welfare. This involves providing clear information about how AI systems function, what data they use, and how decisions impact both individuals and the broader community.\n",
      "\n",
      "4. **Adaptive Policies**: Create adaptive regulatory frameworks that balance individual rights and collective needs. This can include policies that allow for flexibility and adaptation based on societal changes, technological advancements, and social norms. Such frameworks should promote both personal agency and communal benefits.\n",
      "\n",
      "5. **Participatory Design**: Use participatory design methods that involve communities in the development of AI systems. This approach ensures that the perspectives and needs of individuals are considered alongside collective interests, leading to solutions that are more widely accepted and beneficial.\n",
      "\n",
      "6. **Contextual Ethics**: Employ context-sensitive ethical frameworks that consider the specific circumstances of each decision. For instance, in healthcare AI, protecting individual patient autonomy might be prioritized if the individual's health is at stake. In other contexts, like public safety, the collective good may take precedence.\n",
      "\n",
      "7. **Balancing Risks and Benefits**: Evaluate the risks and benefits of AI applications holistically. This includes assessing how individual rights might be infringed upon by actions aimed at benefiting the community, and vice versa. A careful risk-benefit analysis can help to strike a balance that respects both sides.\n",
      "\n",
      "8. **Education and Awareness**: Promote understanding of both individual rights and the importance of collective welfare. By educating users and stakeholders about the interconnectedness of personal and societal interests, individuals may become more receptive to collective welfare initiatives.\n",
      "\n",
      "9. **Multi-Stakeholder Dialogue**: Foster ongoing dialogue among various stakeholders, including ethicists, technologists, policymakers, and the public. This dialogue can help identify potential conflicts and develop collaborative solutions that uphold both individual autonomy and collective welfare.\n",
      "\n",
      "10. **Ethical AI Frameworks**: Develop and implement ethical frameworks for AI that guide decision-making processes. Such frameworks can help navigate ethical dilemmas by providing guidelines that prioritize both individual autonomy and the consideration of collective impacts.\n",
      "\n",
      "By incorporating these strategies, we can work towards an ethical framework for AI that respects personal agency while recognizing the importance of the greater good, ultimately aiming for solutions that benefit both individuals and society as a whole.\n",
      "Competitor: llama3.2:1b\n",
      "\n",
      "Reconciling individual autonomy with collective welfare is a crucial challenge in the development and deployment of artificial intelligence (AI). As AI systems become more complex and influential, there is growing concern about how to balance individual rights and freedoms with the need for collective well-being. Here are some key considerations to help reconcile these tensions:\n",
      "\n",
      "**Individual Autonomy:**\n",
      "\n",
      "1. **Respect for human dignity**: Recognize that individuals have inherent value and dignity, which should be respected in decision-making processes.\n",
      "2. **Consent and informed consent**: Ensure that individuals provide informed and voluntary consent for AI systems to process their data, decisions, or actions.\n",
      "3. **Capacity and cognitive abilities**: Consider the capabilities and limitations of individuals, particularly those with disabilities, when making decisions about AI-driven outcomes.\n",
      "\n",
      "**Collective Welfare:**\n",
      "\n",
      "1. **Common good approach**: Prioritize collective interests over individual goals, recognizing that the well-being of society as a whole is often impacted by AI systems.\n",
      "2. **Transparency and accountability**: Foster transparency in decision-making processes to ensure that individuals understand how their choices are being made and why they were made.\n",
      "3. **Value alignment**: Implement mechanisms to align AI objectives with human values, such as fairness, equality, and justice.\n",
      "\n",
      "**Strategies for Reconciling Autonomy and Welfare:**\n",
      "\n",
      "1. **Distributed design**: Design AI systems with distributed decision-making processes that consider diverse perspectives and expertise, reducing the dominance of individual views.\n",
      "2. **Human oversight and feedback**: Integrate human evaluators into the decision-making process to provide contextually relevant feedback and ensure accountability.\n",
      "3. **Explainability and interpretable AI**: Develop AI systems that can explain their reasoning processes and outcomes, empowering individuals to understand their decisions and take action if necessary.\n",
      "4. **Collaborative governance**: Establish collaborative governance frameworks that involve stakeholders from diverse backgrounds, including experts in ethics, human rights, and relevant regulatory bodies.\n",
      "5. **Risk assessment and mitigation**: Conduct thorough risk assessments for AI systems and develop strategies to mitigate potential harms, ensuring that collective welfare is protected while maintaining individual autonomy.\n",
      "\n",
      "**Key Challenges and Open Questions:**\n",
      "\n",
      "1. **Defining and measuring collective welfare**: Identify metrics and benchmarks to evaluate the impact of AI on society.\n",
      "2. **Balancing innovation with regulation**: Balance the benefits of technological advancements with concerns about individual privacy, security, and accountability.\n",
      "3. **Addressing competing values**: Engage in ongoing dialogue across different societal sectors (e.g., tech companies, academia, policymakers) to foster common understanding of ethical issues related to AI-driven outcomes.\n",
      "\n",
      "In conclusion, reconciling individual autonomy and collective welfare in the context of ethical decision-making in AI requires careful consideration of diverse perspectives, expertise, and values. By adopting strategies such as distributed design, human oversight, and explainability, we can build more equitable and responsible AI systems that prioritize both individual rights and collective well-being.\n"
     ]
    }
   ],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitor}\\n\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Response from competitor 1\n",
      "\n",
      "Reconciling the tension between individual autonomy and collective welfare in ethical decision-making related to artificial intelligence (AI) is a complex challenge that requires a multidimensional approach. Here are several strategies to navigate this tension:\n",
      "\n",
      "1. **Value Alignment**: Develop AI systems that are aligned with human values. This can involve engaging diverse stakeholders in the design and deployment phases to ensure that the systems respect individual autonomy while promoting collective welfare. Understanding the values of both individuals and communities can help create a balanced approach.\n",
      "\n",
      "2. **Transparent Decision-Making**: Foster transparency in AI systems to allow individuals to understand how decisions are made. When people are informed about how their data is used and how decisions affect them, they may feel more empowered and autonomous, thus reducing friction with collective measures that benefit society.\n",
      "\n",
      "3. **Informed Consent**: Implement robust informed consent mechanisms that respect individual autonomy while also outlining how individual choices contribute to collective welfare. This involves providing clear information about how AI systems function, what data they use, and how decisions impact both individuals and the broader community.\n",
      "\n",
      "4. **Adaptive Policies**: Create adaptive regulatory frameworks that balance individual rights and collective needs. This can include policies that allow for flexibility and adaptation based on societal changes, technological advancements, and social norms. Such frameworks should promote both personal agency and communal benefits.\n",
      "\n",
      "5. **Participatory Design**: Use participatory design methods that involve communities in the development of AI systems. This approach ensures that the perspectives and needs of individuals are considered alongside collective interests, leading to solutions that are more widely accepted and beneficial.\n",
      "\n",
      "6. **Contextual Ethics**: Employ context-sensitive ethical frameworks that consider the specific circumstances of each decision. For instance, in healthcare AI, protecting individual patient autonomy might be prioritized if the individual's health is at stake. In other contexts, like public safety, the collective good may take precedence.\n",
      "\n",
      "7. **Balancing Risks and Benefits**: Evaluate the risks and benefits of AI applications holistically. This includes assessing how individual rights might be infringed upon by actions aimed at benefiting the community, and vice versa. A careful risk-benefit analysis can help to strike a balance that respects both sides.\n",
      "\n",
      "8. **Education and Awareness**: Promote understanding of both individual rights and the importance of collective welfare. By educating users and stakeholders about the interconnectedness of personal and societal interests, individuals may become more receptive to collective welfare initiatives.\n",
      "\n",
      "9. **Multi-Stakeholder Dialogue**: Foster ongoing dialogue among various stakeholders, including ethicists, technologists, policymakers, and the public. This dialogue can help identify potential conflicts and develop collaborative solutions that uphold both individual autonomy and collective welfare.\n",
      "\n",
      "10. **Ethical AI Frameworks**: Develop and implement ethical frameworks for AI that guide decision-making processes. Such frameworks can help navigate ethical dilemmas by providing guidelines that prioritize both individual autonomy and the consideration of collective impacts.\n",
      "\n",
      "By incorporating these strategies, we can work towards an ethical framework for AI that respects personal agency while recognizing the importance of the greater good, ultimately aiming for solutions that benefit both individuals and society as a whole.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "Reconciling individual autonomy with collective welfare is a crucial challenge in the development and deployment of artificial intelligence (AI). As AI systems become more complex and influential, there is growing concern about how to balance individual rights and freedoms with the need for collective well-being. Here are some key considerations to help reconcile these tensions:\n",
      "\n",
      "**Individual Autonomy:**\n",
      "\n",
      "1. **Respect for human dignity**: Recognize that individuals have inherent value and dignity, which should be respected in decision-making processes.\n",
      "2. **Consent and informed consent**: Ensure that individuals provide informed and voluntary consent for AI systems to process their data, decisions, or actions.\n",
      "3. **Capacity and cognitive abilities**: Consider the capabilities and limitations of individuals, particularly those with disabilities, when making decisions about AI-driven outcomes.\n",
      "\n",
      "**Collective Welfare:**\n",
      "\n",
      "1. **Common good approach**: Prioritize collective interests over individual goals, recognizing that the well-being of society as a whole is often impacted by AI systems.\n",
      "2. **Transparency and accountability**: Foster transparency in decision-making processes to ensure that individuals understand how their choices are being made and why they were made.\n",
      "3. **Value alignment**: Implement mechanisms to align AI objectives with human values, such as fairness, equality, and justice.\n",
      "\n",
      "**Strategies for Reconciling Autonomy and Welfare:**\n",
      "\n",
      "1. **Distributed design**: Design AI systems with distributed decision-making processes that consider diverse perspectives and expertise, reducing the dominance of individual views.\n",
      "2. **Human oversight and feedback**: Integrate human evaluators into the decision-making process to provide contextually relevant feedback and ensure accountability.\n",
      "3. **Explainability and interpretable AI**: Develop AI systems that can explain their reasoning processes and outcomes, empowering individuals to understand their decisions and take action if necessary.\n",
      "4. **Collaborative governance**: Establish collaborative governance frameworks that involve stakeholders from diverse backgrounds, including experts in ethics, human rights, and relevant regulatory bodies.\n",
      "5. **Risk assessment and mitigation**: Conduct thorough risk assessments for AI systems and develop strategies to mitigate potential harms, ensuring that collective welfare is protected while maintaining individual autonomy.\n",
      "\n",
      "**Key Challenges and Open Questions:**\n",
      "\n",
      "1. **Defining and measuring collective welfare**: Identify metrics and benchmarks to evaluate the impact of AI on society.\n",
      "2. **Balancing innovation with regulation**: Balance the benefits of technological advancements with concerns about individual privacy, security, and accountability.\n",
      "3. **Addressing competing values**: Engage in ongoing dialogue across different societal sectors (e.g., tech companies, academia, policymakers) to foster common understanding of ethical issues related to AI-driven outcomes.\n",
      "\n",
      "In conclusion, reconciling individual autonomy and collective welfare in the context of ethical decision-making in AI requires careful consideration of diverse perspectives, expertise, and values. By adopting strategies such as distributed design, human oversight, and explainability, we can build more equitable and responsible AI systems that prioritize both individual rights and collective well-being.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are judging a competition between 2 competitors.\n",
      "Each model has been given this question:\n",
      "\n",
      "How do you reconcile the tension between individual autonomy and collective welfare in the context of ethical decision-making in artificial intelligence?\n",
      "\n",
      "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
      "Respond with JSON, and only JSON, with the following format:\n",
      "{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}\n",
      "\n",
      "Here are the responses from each competitor:\n",
      "\n",
      "# Response from competitor 1\n",
      "\n",
      "Reconciling the tension between individual autonomy and collective welfare in ethical decision-making related to artificial intelligence (AI) is a complex challenge that requires a multidimensional approach. Here are several strategies to navigate this tension:\n",
      "\n",
      "1. **Value Alignment**: Develop AI systems that are aligned with human values. This can involve engaging diverse stakeholders in the design and deployment phases to ensure that the systems respect individual autonomy while promoting collective welfare. Understanding the values of both individuals and communities can help create a balanced approach.\n",
      "\n",
      "2. **Transparent Decision-Making**: Foster transparency in AI systems to allow individuals to understand how decisions are made. When people are informed about how their data is used and how decisions affect them, they may feel more empowered and autonomous, thus reducing friction with collective measures that benefit society.\n",
      "\n",
      "3. **Informed Consent**: Implement robust informed consent mechanisms that respect individual autonomy while also outlining how individual choices contribute to collective welfare. This involves providing clear information about how AI systems function, what data they use, and how decisions impact both individuals and the broader community.\n",
      "\n",
      "4. **Adaptive Policies**: Create adaptive regulatory frameworks that balance individual rights and collective needs. This can include policies that allow for flexibility and adaptation based on societal changes, technological advancements, and social norms. Such frameworks should promote both personal agency and communal benefits.\n",
      "\n",
      "5. **Participatory Design**: Use participatory design methods that involve communities in the development of AI systems. This approach ensures that the perspectives and needs of individuals are considered alongside collective interests, leading to solutions that are more widely accepted and beneficial.\n",
      "\n",
      "6. **Contextual Ethics**: Employ context-sensitive ethical frameworks that consider the specific circumstances of each decision. For instance, in healthcare AI, protecting individual patient autonomy might be prioritized if the individual's health is at stake. In other contexts, like public safety, the collective good may take precedence.\n",
      "\n",
      "7. **Balancing Risks and Benefits**: Evaluate the risks and benefits of AI applications holistically. This includes assessing how individual rights might be infringed upon by actions aimed at benefiting the community, and vice versa. A careful risk-benefit analysis can help to strike a balance that respects both sides.\n",
      "\n",
      "8. **Education and Awareness**: Promote understanding of both individual rights and the importance of collective welfare. By educating users and stakeholders about the interconnectedness of personal and societal interests, individuals may become more receptive to collective welfare initiatives.\n",
      "\n",
      "9. **Multi-Stakeholder Dialogue**: Foster ongoing dialogue among various stakeholders, including ethicists, technologists, policymakers, and the public. This dialogue can help identify potential conflicts and develop collaborative solutions that uphold both individual autonomy and collective welfare.\n",
      "\n",
      "10. **Ethical AI Frameworks**: Develop and implement ethical frameworks for AI that guide decision-making processes. Such frameworks can help navigate ethical dilemmas by providing guidelines that prioritize both individual autonomy and the consideration of collective impacts.\n",
      "\n",
      "By incorporating these strategies, we can work towards an ethical framework for AI that respects personal agency while recognizing the importance of the greater good, ultimately aiming for solutions that benefit both individuals and society as a whole.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "Reconciling individual autonomy with collective welfare is a crucial challenge in the development and deployment of artificial intelligence (AI). As AI systems become more complex and influential, there is growing concern about how to balance individual rights and freedoms with the need for collective well-being. Here are some key considerations to help reconcile these tensions:\n",
      "\n",
      "**Individual Autonomy:**\n",
      "\n",
      "1. **Respect for human dignity**: Recognize that individuals have inherent value and dignity, which should be respected in decision-making processes.\n",
      "2. **Consent and informed consent**: Ensure that individuals provide informed and voluntary consent for AI systems to process their data, decisions, or actions.\n",
      "3. **Capacity and cognitive abilities**: Consider the capabilities and limitations of individuals, particularly those with disabilities, when making decisions about AI-driven outcomes.\n",
      "\n",
      "**Collective Welfare:**\n",
      "\n",
      "1. **Common good approach**: Prioritize collective interests over individual goals, recognizing that the well-being of society as a whole is often impacted by AI systems.\n",
      "2. **Transparency and accountability**: Foster transparency in decision-making processes to ensure that individuals understand how their choices are being made and why they were made.\n",
      "3. **Value alignment**: Implement mechanisms to align AI objectives with human values, such as fairness, equality, and justice.\n",
      "\n",
      "**Strategies for Reconciling Autonomy and Welfare:**\n",
      "\n",
      "1. **Distributed design**: Design AI systems with distributed decision-making processes that consider diverse perspectives and expertise, reducing the dominance of individual views.\n",
      "2. **Human oversight and feedback**: Integrate human evaluators into the decision-making process to provide contextually relevant feedback and ensure accountability.\n",
      "3. **Explainability and interpretable AI**: Develop AI systems that can explain their reasoning processes and outcomes, empowering individuals to understand their decisions and take action if necessary.\n",
      "4. **Collaborative governance**: Establish collaborative governance frameworks that involve stakeholders from diverse backgrounds, including experts in ethics, human rights, and relevant regulatory bodies.\n",
      "5. **Risk assessment and mitigation**: Conduct thorough risk assessments for AI systems and develop strategies to mitigate potential harms, ensuring that collective welfare is protected while maintaining individual autonomy.\n",
      "\n",
      "**Key Challenges and Open Questions:**\n",
      "\n",
      "1. **Defining and measuring collective welfare**: Identify metrics and benchmarks to evaluate the impact of AI on society.\n",
      "2. **Balancing innovation with regulation**: Balance the benefits of technological advancements with concerns about individual privacy, security, and accountability.\n",
      "3. **Addressing competing values**: Engage in ongoing dialogue across different societal sectors (e.g., tech companies, academia, policymakers) to foster common understanding of ethical issues related to AI-driven outcomes.\n",
      "\n",
      "In conclusion, reconciling individual autonomy and collective welfare in the context of ethical decision-making in AI requires careful consideration of diverse perspectives, expertise, and values. By adopting strategies such as distributed design, human oversight, and explainability, we can build more equitable and responsible AI systems that prioritize both individual rights and collective well-being.\n",
      "\n",
      "\n",
      "\n",
      "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\n"
     ]
    }
   ],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"results\": [\"1\", \"2\"]}\n"
     ]
    }
   ],
   "source": [
    "# Judgement time!\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    messages=judge_messages,\n",
    ")\n",
    "results = response.choices[0].message.content\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: gpt-4o-mini\n",
      "Rank 2: llama3.2:1b\n"
     ]
    }
   ],
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            are common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
